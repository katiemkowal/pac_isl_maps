{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03fa2f8-6bf0-4b25-9331-7023b124a47d",
   "metadata": {},
   "source": [
    "# Practical to Compare How Different Bias Correction Techniques Compare for Seasonal Forecasts\n",
    "In this practical, we will use some forecast models to generate some seasonal precipitation forecasts, and then assess how different techniques compare to bias correct these seasonal precipitation forecasts.\n",
    "\n",
    "Bias correction techniques assessed will include **(1)** Canonical Correlation Analysis (CCA), which bias corrects the forecasts using a large scale correlation patterns over a spatial domain, **(2)** Extended Logistic Regression (ELR), and **(3)** Ensemble Probabalistic Output Extreme Learning Machine (EPOELM), which are two grid-based bias-correction techniques that do a grid by grid cell adjustment to the raw forecasts.\n",
    "\n",
    "**This notebook should be run in the intdesk_train environment - check your kernel (upper righthand corner) is set to 'intdesk_train', so you have all necessary libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc67c21-4a85-4ff0-b233-a71337ca1497",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c35e1-8def-4326-ad50-afd23e1be538",
   "metadata": {},
   "source": [
    "import xcast as xc\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import os\n",
    "import time\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from cartopy.feature import NaturalEarthFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c3b9f-6716-442e-bf51-6175b0ca3e1a",
   "metadata": {},
   "source": [
    "## Project Directory Setup\n",
    "setup the folder where you want to work for this project\n",
    "\n",
    "either set project_dir equal to the location of your working directory, e.g. \"/Users/katie/Desktop/pacisl_training\" or place this notebook in the folder where you want your project to live and set project_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cc9777-b35e-485d-a336-7062a6a41e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Directory is Located in /Users/katie/Desktop/pacisl_training\n"
     ]
    }
   ],
   "source": [
    "project_dir = \"/Users/katie/Desktop/pacisl_training\"#os.getcwd()\n",
    "print('Project Directory is Located in ' + project_dir)\n",
    "\n",
    "#makes subdirectores to organize your work within the project if they don't already exist\n",
    "os.makedirs(os.path.join(project_dir, 'practical_data'), exist_ok = True)\n",
    "data_dir = os.path.join(project_dir, 'practical_data')\n",
    "os.makedirs(os.path.join(project_dir, 'practical_figures'), exist_ok = True)\n",
    "figure_dir = os.path.join(project_dir, 'practical_figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e0298-a008-428a-8261-b1b2c8dd580b",
   "metadata": {},
   "source": [
    "### Add all of your data for this practical into your 'practical_data' folder now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f4439-ba61-4fc7-8556-68eff70816ff",
   "metadata": {},
   "source": [
    "## Setup Your Constants: Spatial Extents and Dates\n",
    "\n",
    "**(1) initialization date**: Make sure this date is not set for a future month but in a present or past month, and then seasonal forecasts will be created for 3 target periods following that month. For instance if you pick (2023,8,1) as your initialization date, you will evaluate forecasts over Sep-Nov, Oct-Dec, and Dec-Feb.\n",
    "\n",
    "**(2) region of interest**: Several coordinates have been setup in this cell. Make sure your region_coords variable is equal to the name of one of the coordinate dictionary entries in this cell, and then name that region as you like, e.g. region_coords = solomon_coordinates, region_of_interest = 'Solomon Islands'.\n",
    "You can adjust the coordinate values as you like in the dictionaries if you want to play around with the predictand extent, just remember to keep the naming consistent.\n",
    "\n",
    "If you found a particular spatial extent for your predictors improved your CCA bias correction technique in the CCA_practice notebook, feel free to update the predictor_train_extent coordinates below, otherwise can leave as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2913f879-c518-4fbc-a5f4-a5704e0ef818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PICK YOUR DATE you want to initialize the model, e.g. your current date\n",
    "initial_date = (2023, 8, 1)\n",
    "\n",
    "#REGION OF INTEREST\n",
    "#some predefined zones, update the numbers or add another zone following the same labelling structure\n",
    "pacislands_coordinates = {\n",
    "    'west': 130,\n",
    "    'east': 205,\n",
    "    'north': 8,\n",
    "    'south': -20\n",
    "    }\n",
    "\n",
    "chuuk_coordinates = {\n",
    "    'west': 151,\n",
    "    'east': 153,\n",
    "    'north': 8,\n",
    "    'south': 6\n",
    "    }\n",
    "\n",
    "fiji_coordinates = {\n",
    "    'west':  177,\n",
    "    'east': 182,  \n",
    "    'north': -15,  \n",
    "    'south': -20}\n",
    "\n",
    "kiribati_coordinates = {\n",
    "        'west':  202,\n",
    "        'east': 203,  \n",
    "        'north': 3,  \n",
    "        'south': 1}\n",
    "\n",
    "solomon_coordinates = {\n",
    "        'west':  155,\n",
    "        'east': 167,  \n",
    "        'north': -6,  \n",
    "        'south': -13}\n",
    "\n",
    "png_coordinates = {\n",
    "        'west':  130,\n",
    "        'east': 156,  \n",
    "        'north': 1,  \n",
    "        'south': -12}\n",
    "        \n",
    "palau_coordinates = {\n",
    "        'west':  133,\n",
    "        'east': 135,  \n",
    "        'north': 8,  \n",
    "        'south': 6\n",
    "}\n",
    "        \n",
    "vanuatu_coordinates = {\n",
    "        'west':  165,\n",
    "        'east': 170,  \n",
    "        'north': -12,  \n",
    "        'south': -20\n",
    "}\n",
    "\n",
    "samoa_coordinates = {\n",
    "        'west':  187,\n",
    "        'east': 191,  \n",
    "        'north': -13,  \n",
    "        'south': -15\n",
    "}\n",
    "\n",
    "tuvalu_coordinates = {\n",
    "        'west':  178,\n",
    "        'east': 180,  \n",
    "        'north': -8,  \n",
    "        'south': -9\n",
    "}\n",
    "\n",
    "\n",
    "### PICK YOUR TARGET REGION OF INTEREST\n",
    "region_of_interest = 'Vanuatu' #how you want to name your region (can include spaces)\n",
    "region_coords = vanuatu_coordinates #name of the coordinates to use for your region, as defined above\n",
    "\n",
    "### YOUR PREDICTOR TRAINING ZONE\n",
    "\n",
    "predictor_train_extent = {\n",
    "    'west': 120,\n",
    "    'east': 210,\n",
    "    'north': 10,\n",
    "    'south': -30\n",
    "}\n",
    "predictor_train_extent_name = 'Pacific'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c59cd-8b6f-4d52-a92e-bf41593ffbeb",
   "metadata": {},
   "source": [
    "## Prepare Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dea95a3-7f9b-4ae0-b84c-10989965c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target seasons to forecast\n",
      "['Sep-Nov', 'Oct-Dec', 'Nov-Jan']\n"
     ]
    }
   ],
   "source": [
    "#this cell is setup to calculate your target forecast months based on your initialization date\n",
    "#the forecast months are currently seto to be 1-3, 2-4 and 3-5 months ahead\n",
    "number_to_month_name_dictionary = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec',\n",
    "    0: 'Dec'\n",
    "}\n",
    "\n",
    "leads = [['1', '3'],['2', '4'], ['3','5']]\n",
    "initial_month = dt.datetime(*initial_date).month\n",
    "initial_month_name = number_to_month_name_dictionary[initial_month]\n",
    "target_seas = []\n",
    "for l in leads:\n",
    "    target_low = number_to_month_name_dictionary[(initial_month + float(l[0]))%12]\n",
    "    target_high = number_to_month_name_dictionary[(initial_month + float(l[1]))%12]\n",
    "    target_seas.append('-'.join([target_low, target_high]))\n",
    "print('Target seasons to forecast')\n",
    "print(target_seas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0bea78-40e3-4aab-94aa-28a06a997821",
   "metadata": {},
   "source": [
    "### Load Observations and Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed12bd-902e-4330-9b5e-ad9b8e75e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_leads = xr.open_dataset(os.path.join(data_dir, '_'.join([initial_month_name, 'threeseas_CMORPH_precip.nc'])))\n",
    "\n",
    "#train the model on observations over a grid slightly larger than the region of interest\n",
    "#this could be updated for later fine-tuning, but calculated here to keep it simple for now\n",
    "predictand_train_extent = {\n",
    "    'west':  region_coords['west']-5,\n",
    "        'east': region_coords['east']+5,  \n",
    "        'north': region_coords['north']+3,  \n",
    "        'south': region_coords['south']-2\n",
    "}\n",
    "obs_leads = obs_leads.sel(X=slice(predictand_train_extent['west'], predictand_train_extent['east']),\n",
    "                          Y=slice(predictand_train_extent['south'], predictand_train_extent['north']))\n",
    "print(obs_leads)\n",
    "\n",
    "# read in hindcast and forecast data\n",
    "hindcast_data = xr.open_dataset(os.path.join(data_dir, '_'.join([initial_month_name, 'threeseas_NMME_hcst_precip.nc'])))\n",
    "forecast_data = xr.open_dataset(os.path.join(data_dir, '_'.join([initial_month_name, 'threeseas_NMME_fcst_precip.nc'])))\n",
    "\n",
    "hindcast_data = hindcast_data.sel(X=slice(predictor_train_extent['west'], predictor_train_extent['east']),\n",
    "                          Y=slice(predictor_train_extent['south'], predictor_train_extent['north']))\n",
    "forecast_data = forecast_data.sel(X=slice(predictor_train_extent['west'], predictor_train_extent['east']),\n",
    "                          Y=slice(predictor_train_extent['south'], predictor_train_extent['north']))\n",
    "\n",
    "#read in the ocean mask for the region (makes it easier to see the plots)\n",
    "msk = xr.open_dataset(os.path.join(data_dir, 'pacific_mask.nc'))\n",
    "mskk = msk.amask.expand_dims({'M':[0]})\n",
    "mskk = mskk.assign_coords({'lon': [i + 360 if i <= 0 else i for i in mskk.coords['lon'].values]}).sortby('lon').drop_duplicates('lon')\n",
    "mskk = mskk.rename({'lon':'X', 'lat':'Y', 'time':'T'})\n",
    "mskk = xc.regrid(mskk, obs_leads.X, obs_leads.Y)\n",
    "mask_missing = mskk.mean('T', skipna=False).mean('M', skipna=False)\n",
    "mask_missing = xr.ones_like(mask_missing).where(~np.isnan(mask_missing), other=np.nan )\n",
    "\n",
    "if region_coords == chuuk_coordinates:\n",
    "    obs_leads = obs_leads.copy()\n",
    "else:\n",
    "    obs_leads = obs_leads * mask_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399b1ff-a0d4-4d08-bae2-1f51b7a948ec",
   "metadata": {},
   "source": [
    "#### Check your region of interest is what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f44c8-4a08-4ab2-a82b-c5edad8cfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_check = obs_leads.sel(X=slice(predictand_train_extent['west'], predictand_train_extent['east']),\n",
    "                          Y=slice(predictand_train_extent['south'], predictand_train_extent['north']))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6,2), \n",
    "                         subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)})\n",
    "\n",
    "# Your plotting code here using the specific model and season\n",
    "xplot = obs_check.isel(T=0, L=2).precip.plot(ax=axes,\n",
    "                                 transform=ccrs.PlateCarree())\n",
    "axes.coastlines()\n",
    "c = axes.coastlines()\n",
    "# Add country borders\n",
    "axes.add_feature(NaturalEarthFeature(category='cultural', name='admin_0_countries', \n",
    "                                    scale='50m', edgecolor='black', facecolor='none'))\n",
    "# Set the extent to cover the specific area\n",
    "axes.set_extent([region_coords['west'], region_coords['east'], region_coords['south'], region_coords['north']], crs=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfb4d2-0364-4554-8158-de905d72afaa",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf257f8a-075f-494e-8b3a-dfa234118667",
   "metadata": {},
   "source": [
    "### Bias correct raw model outputs using CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca367e-f78d-4b6d-881b-5286047ea58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cca_fcsts_prob, cca_fcsts_det, cca_hcasts_det, cca_hcasts_prob, obs_to_test, raw_to_test = [],[],[],[],[],[]\n",
    "\n",
    "for l in np.unique(hindcast_data.L):\n",
    "    obs = obs_leads.sel(L=l).precip\n",
    "    model = hindcast_data.sel(L=l).precip\n",
    "    fmodel = forecast_data.sel(L=l).precip\n",
    "\n",
    "    #run CCA\n",
    "    hindcasts_det, hindcasts_prob, obs_test, raw_test = [], [], [], []\n",
    "    i=1\n",
    "    for xtrain, ytrain, xtest, ytest in xc.CrossValidator(model, obs, window=5):\n",
    "        print(\"window {}\".format(i))\n",
    "        i += 1\n",
    "        reg_CCA = xc.CCA(search_override=(5,\n",
    "                                      5,\n",
    "                                     3))\n",
    "        reg_CCA.fit(xtrain, ytrain)\n",
    "        preds = reg.predict(xtest)\n",
    "        probs =  reg.predict_proba(xtest)\n",
    "        obs_test.append(ytest)\n",
    "        raw_test.append(xtest)\n",
    "        hindcasts_det.append(preds)\n",
    "        hindcasts_prob.append(probs)\n",
    "    hindcasts_det = xr.concat(hindcasts_det, 'T')\n",
    "    hindcasts_prob = xr.concat(hindcasts_prob, 'T')\n",
    "    obs_test = xr.concat(obs_test, 'T')\n",
    "    raw_test = xr.concat(raw_test, 'T')\n",
    "    \n",
    "    fprobs =  reg.predict_proba(fmodel)\n",
    "    \n",
    "    cca_fcsts_prob.append(fprobs)\n",
    "    cca_hcasts_det.append(hindcasts_det)\n",
    "    cca_hcasts_prob.append(hindcasts_prob)\n",
    "    obs_to_test.append(obs_test)\n",
    "    raw_to_test.append(raw_test)\n",
    "\n",
    "cca_fcsts_prob = xr.concat(cca_fcsts_prob, dim = 'L')\n",
    "cca_hcasts_det = xr.concat(cca_hcasts_det, dim = 'L')\n",
    "cca_hcasts_prob = xr.concat(cca_hcasts_prob, dim = 'L')\n",
    "obs_to_test = xr.concat(obs_to_test, dim = 'L')\n",
    "raw_to_test = xr.concat(raw_to_test, dim = 'L')\n",
    "print('cca processing time is ' + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c594ac5-46e5-4e7e-a81f-718996cb22e1",
   "metadata": {},
   "source": [
    "### Bias correct raw model outputs using grid-based techniques (ELR, EPOELM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebed98-5498-4d37-ba39-e16cc722dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "elr_fcsts_prob, elr_fcsts_det, elr_hcasts_det, elr_hcasts_prob = [], [], [], []\n",
    "epoelm_fcsts_prob, epoelm_fcsts_det, epoelm_hcasts_det, epoelm_hcasts_prob = [], [], [], []\n",
    "obs_to_test_grid, raw_to_test_grid = [],[]\n",
    "\n",
    "for l in np.unique(hindcast_data.L):\n",
    "    obs = obs_leads.sel(L=l).precip\n",
    "    model = hindcast_data.sel(L=l).precip\n",
    "    fmodel = forecast_data.sel(L=l).precip\n",
    "    \n",
    "    model_regrid = xc.regrid(model, obs.X, obs.Y)\n",
    "    fmodel_regrid = xc.regrid(fmodel, obs.X, obs.Y)\n",
    "\n",
    "    obs, model_regrid = xc.match(obs, model_regrid)\n",
    "\n",
    "    #run ELR, EPOELM\n",
    "    hindcasts_det_ELR, hindcasts_prob_ELR, hindcasts_det_EPOELM, hindcasts_prob_EPOELM, obs_test_grid, raw_test_grid = [], [], [], [], [], []\n",
    "    i=1\n",
    "    for xtrain, ytrain, xtest, ytest in xc.CrossValidator(model_regrid, obs_regrid, window=5):\n",
    "        print(\"window {}\".format(i))\n",
    "        i += 1\n",
    "        reg_ELR = xc.ELR()\n",
    "        reg_ELR.fit(xtrain, ytrain)\n",
    "        \n",
    "        reg_EPOELM = xc.EPOELM()\n",
    "        reg_EPOELM.fit(xtrain, ytrain)\n",
    "        \n",
    "        preds_ELR = reg_ELR.predict(xtest)\n",
    "        probs_ELR =  reg_ELR.predict_proba(xtest)\n",
    "        preds_EPOELM = reg_EPOELM.predict(xtest)\n",
    "        probs_EPOELM =  reg_EPOELM.predict_proba(xtest)\n",
    "        \n",
    "        obs_test_grid.append(ytest)\n",
    "        raw_test_grid.append(xtest)\n",
    "        hindcasts_det_ELR.append(preds_ELR)\n",
    "        hindcasts_prob_ELR.append(probs_ELR)\n",
    "        hindcasts_det_EPOELM.append(preds_EPOELM)\n",
    "        hindcasts_prob_EPOELM.append(probs_EPOELM)\n",
    "    hindcasts_det_ELR = xr.concat(hindcasts_det_ELR, 'T')\n",
    "    hindcasts_prob_ELR = xr.concat(hindcasts_prob_ELR, 'T')\n",
    "    hindcasts_det_EPOELM = xr.concat(hindcasts_det_EPOELM, 'T')\n",
    "    hindcasts_prob_EPOELM = xr.concat(hindcasts_prob_EPOELM, 'T')\n",
    "    obs_test_grid = xr.concat(obs_test_grid, 'T')\n",
    "    raw_test_grid = xr.concat(raw_test_grid, 'T')\n",
    "    \n",
    "    fprobs_ELR =  reg_ELR.predict_proba(fmodel_regrid)\n",
    "    fprobs_EPOELM =  reg_EPOELM.predict_proba(fmodel_regrid)\n",
    "    \n",
    "    elr_fcsts_prob.append(fprobs_ELR)\n",
    "    elr_hcasts_det.append(hindcasts_det_ELR)\n",
    "    elr_hcasts_prob.append(hindcasts_prob_ELR)\n",
    "    epoelm_fcsts_prob.append(fprobs_EPOELM)\n",
    "    epoelm_hcasts_det.append(hindcasts_det_EPOELM)\n",
    "    epoelm_hcasts_prob.append(hindcasts_prob_EPOELM)\n",
    "    obs_to_test_grid.append(obs_test_grid)\n",
    "    raw_to_test_grid.append(raw_test_grid)\n",
    "\n",
    "elr_fcsts_prob = xr.concat(elr_fcsts_prob, dim = 'L')\n",
    "elr_hcasts_det = xr.concat(elr_hcasts_det, dim = 'L')\n",
    "elr_hcasts_prob = xr.concat(elr_hcasts_prob, dim = 'L')\n",
    "epoelm_fcsts_prob = xr.concat(epoelm_fcsts_prob, dim = 'L')\n",
    "epoelm_hcasts_det = xr.concat(epoelm_hcasts_det, dim = 'L')\n",
    "epoelm_hcasts_prob = xr.concat(epoelm_hcasts_prob, dim = 'L')\n",
    "obs_to_test_grid = xr.concat(obs_to_test_grid, dim = 'L')\n",
    "raw_to_test_grid = xr.concat(raw_to_test_grid, dim = 'L')\n",
    "print('cca processing time is ' + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08262abc-fb04-4a7f-b611-0fcc1bac7268",
   "metadata": {},
   "source": [
    "## Evaluate Performance of Raw vs Bias Corrected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3aa91a-aded-47f3-a14b-0254497f8bf2",
   "metadata": {},
   "source": [
    "#### Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7b349-06d2-4de8-bf3e-a8da304171b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#calculate pearson correlation score for hindcasts\n",
    "pearson_cca, pearson_elr, pearson_epoelm, pearson_raw = [], [], [], []\n",
    "for l, lead in enumerate(np.unique(hindcast_data.L.values)):\n",
    "    cca_pearson_calc = xc.Pearson(cca_hcasts_det.isel(L=l),obs_to_test.isel(L=l))\n",
    "    cca_pearson_calc = cca_pearson_calc.expand_dims({'M':['NMME CCA']})\n",
    "\n",
    "    elr_pearson_calc = xc.Pearson(elr_hcasts_det.isel(L=l),obs_to_test_grid.isel(L=l))\n",
    "    elr_pearson_calc = elr_pearson_calc.expand_dims({'M':['NMME ELR']})\n",
    "\n",
    "    epoelm_pearson_calc = xc.Pearson(epoelm_hcasts_det.isel(L=l),obs_to_test_grid.isel(L=l))\n",
    "    epoelm_pearson_calc = epoelm_pearson_calc.expand_dims({'M':['NMME EPOELM']})\n",
    "\n",
    "    hindcast_raw = raw_to_test_grid * mask_missing\n",
    "    \n",
    "    #calc pearson correlation\n",
    "    pearson_raw_calc = []\n",
    "    for m, model in enumerate(np.unique(hindcast_raw.M.values)):\n",
    "        pearson_raw_c = xc.Pearson(hindcast_raw.sel(M=model).expand_dims({'M':[model]}), \n",
    "                                           obs_leads.isel(L=l).precip)\n",
    "        pearson_raw_c = pearson_raw_c.expand_dims({'M':[model + ' Raw']})\n",
    "        pearson_raw_calc.append(pearson_raw_c)\n",
    "    pearson_raw_calc = xr.concat(pearson_raw_calc, dim = 'M')\n",
    "    pearson_cca.append(cca_pearson_calc)\n",
    "    pearson_raw.append(pearson_raw_calc)\n",
    "    pearson_elr.append(elr_pearson_calc)\n",
    "    pearson_epoelm.append(epoelm_pearson_calc)\n",
    "pearson_cca = xr.concat(pearson_cca, dim = 'L')\n",
    "pearson_elr = xr.concat(pearson_elr, dim = 'L')\n",
    "pearson_epoelm = xr.concat(pearson_epoelm, dim = 'L')\n",
    "pearson_raw = xr.concat(pearson_raw, dim = 'L')\n",
    "pearsons = xr.concat([pearson_cca, pearson_raw, pearson_epoelm, pearson_elr], dim = 'M')\n",
    "print('Pearson processing time is ' + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da599f87-9ade-49b5-8041-1511a9f31930",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.unique(pearsons.M.values)\n",
    "models = np.flip(models, axis = 0)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(models), ncols=len(target_seas), figsize=(10, (len(models))*2 + 2), \n",
    "                         subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)})\n",
    "\n",
    "# Set the extent to cover the entire world\n",
    "for ax in axes.flat:\n",
    "    ax.set_global()\n",
    "\n",
    "for j, model in enumerate(models):\n",
    "    for i, season in enumerate(target_seas):\n",
    "        ax = axes[j, i]\n",
    "        # Your plotting code here using the specific model and season\n",
    "        xplot = pearsons.isel(L=i, M=j).plot(ax=ax,\n",
    "                                              transform=ccrs.PlateCarree(),\n",
    "                                              cmap='coolwarm', levels=21, vmin=-1, vmax=1, add_colorbar=False)\n",
    "        ax.coastlines()\n",
    "        c = ax.coastlines()\n",
    "        c = ax.gridlines(draw_labels=True, linewidth=0.3)\n",
    "        c.right_labels = False\n",
    "        c.top_labels = False \n",
    "        # Add country borders\n",
    "        ax.add_feature(NaturalEarthFeature(category='cultural', name='admin_0_countries', \n",
    "                                            scale='50m', edgecolor='black', facecolor='none'))\n",
    "        # Set the extent to cover the specific area\n",
    "        ax.set_extent([region_coords['west'], region_coords['east'], region_coords['south'], region_coords['north']], crs=ccrs.PlateCarree())\n",
    "        ax.set_title(f'{model} - {season}')\n",
    "\n",
    "# Add a single horizontal colorbar below the panel plot\n",
    "cbar_ax = fig.add_axes([0.15, 0.002, 0.6, 0.02])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(xplot, cax=cbar_ax, orientation='horizontal', shrink =1, pad = 0.3)\n",
    "cbar.set_label(region_of_interest + ' Pearson Correlation', fontsize=13)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(left=0.05, right=0.9, top=0.95, bottom=0.07, wspace=0.01, hspace=0.2)\n",
    "\n",
    "# Show plot\n",
    "plt.savefig(os.path.join(figure_dir, '_'.join([initial_month_name, region_of_interest, 'pearson_methodcomp'])), bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10137c95-1976-438a-a515-cc65786f0fa8",
   "metadata": {},
   "source": [
    "#### GROCS\n",
    "to run this code we need a couple of functions to help transform the observational data into tercile categories\n",
    "make sure to add 'onehotupdate.py' to the function folder where you pull it from in the next step. You can make the function folder the same folder as your project directory, just make sure the folder name is where this file is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c5c80-4b83-4a43-9a39-402cac497234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the necessary functions\n",
    "import importlib.util\n",
    "\n",
    "#onehotupdate.py file and where it is located\n",
    "function_folder = \"/cpc/int_desk/pac_isl/analysis/xcast/seasonal/onehotupdate.py\"\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "\"onehotupdate\", function_folder)    \n",
    "\n",
    "onehot = importlib.util.module_from_spec(spec) \n",
    "spec.loader.exec_module(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df358690-b9f4-4f6f-b15a-5fcc794c02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocs_cca, grocs_elr, grocs_epoelm = [], [], []\n",
    "for l, lead in enumerate(np.unique(hindcast_data.L.values)):\n",
    "\n",
    "    hind_prob_cca = xc.gaussian_smooth(cca_hcasts_prob.isel(L=l), kernel=3)\n",
    "    hind_prob_elr = xc.gaussian_smooth(elr_hcasts_prob.isel(L=l), kernel=3)\n",
    "    hind_prob_epoelm = xc.gaussian_smooth(epoelm_hcasts_prob.isel(L=l), kernel=3)\n",
    "    obs = xc.gaussian_smooth(obs_to_test.isel(L=l), kernel=3)\n",
    "\n",
    "    #transform obs into tercile based categories\n",
    "    ohc = onehot.OneHotEncoder() \n",
    "    ohc.fit(obs)\n",
    "    T = ohc.transform(obs)\n",
    "    clim = xr.ones_like(T) * 0.333\n",
    "    \n",
    "    grocs_cca_l = xc.GROCS(hind_prob_cca, T)\n",
    "    grocs_elr_l = xc.GROCS(hind_prob_elr, T)\n",
    "    grocs_epoelm_l = xc.GROCS(hind_prob_epoelm, T)\n",
    "    grocs_cca_l = grocs_cca_l.expand_dims({'M':['NMME CCA']})\n",
    "    grocs_elr_l = grocs_elr_l.expand_dims({'M':['NMME ELR']})\n",
    "    grocs_epoelm_l = grocs_epoelm_l.expand_dims({'M':['NMME EPOELM']})\n",
    "    grocs_cca.append(grocs_cca_l)\n",
    "    grocs_elr.append(grocs_elr_l)\n",
    "    grocs_epoelm.append(grocs_epoelm_l)\n",
    "\n",
    "grocs_cca = xr.concat(grocs_cca, dim = 'L')\n",
    "grocs_elr = xr.concat(grocs_elr, dim = 'L')\n",
    "grocs_epoelm = xr.concat(grocs_epoelm, dim = 'L')\n",
    "grocs = xr.concat([grocs_cca, grocs_elr, grocs_epoelm], dim = 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdaad6-cb8c-4742-a492-bb8246919fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.unique(grocs.M.values)\n",
    "print(target_seas)\n",
    "fig, axes = plt.subplots(nrows = len(models), ncols=len(target_seas), figsize=(10, (len(models))*2 + 2), \n",
    "                         subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)})\n",
    "\n",
    "# Set the extent to cover the entire world\n",
    "for ax in axes.flat:\n",
    "    ax.set_global()\n",
    "for j, model in enumerate(grocs.M.values):\n",
    "    for i, season in enumerate(target_seas):\n",
    "        ax = axes[i]\n",
    "        # Your plotting code here using the specific model and season\n",
    "        xplot = grocs.isel(L=i, M=j).plot(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                              cmap='coolwarm', levels=21, vmin=0, vmax=1, add_colorbar=False)\n",
    "        ax.coastlines()\n",
    "        c = ax.coastlines()\n",
    "        c = ax.gridlines(draw_labels=True, linewidth=0.3)\n",
    "        c.right_labels = False\n",
    "        c.top_labels = False \n",
    "        # Add country borders\n",
    "        ax.add_feature(NaturalEarthFeature(category='cultural', name='admin_0_countries', \n",
    "                                            scale='50m', edgecolor='black', facecolor='none'))\n",
    "        # Set the extent to cover the specific area\n",
    "        ax.set_extent([region_coords['west'], region_coords['east'], region_coords['south'], region_coords['north']], crs=ccrs.PlateCarree())\n",
    "        ax.set_title(f'{model} - {season}')\n",
    "\n",
    "# Add a single horizontal colorbar below the panel plot\n",
    "cbar_ax = fig.add_axes([0.15, 0.002, 0.6, 0.02])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(xplot, cax=cbar_ax, orientation='horizontal', shrink =1, pad = 0.3)\n",
    "cbar.set_label(region_of_interest + ' GROCS', fontsize=13)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(left=0.05, right=0.9, top=0.95, bottom=0.05, wspace=0.01, hspace=0.2)\n",
    "\n",
    "# Show plot\n",
    "plt.savefig(os.path.join(figure_dir, '_'.join([initial_month_name, region_of_interest, 'GROCS_methodcomp'])), bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cacce-dadd-4723-a756-d1458b329762",
   "metadata": {},
   "source": [
    "## Plot some Probabalistic Forecasts Using Bias Correction Technique of Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b73179-ada4-4e77-b935-f776d9897d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose bias correction technique, either 'cca', 'elr', or 'epoelm'\n",
    "bias_correct = 'cca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6660e-17d3-44eb-9321-1fe2e8e97d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bias_correct == 'cca':\n",
    "    fcsts_prob = cca_fcsts_prob\n",
    "elif bias_correct == 'elr':\n",
    "    fcsts_prob = elr_fcsts_prob\n",
    "elif bias_correct == 'epoelm':\n",
    "    fcsts_prob = epoelm_fcsts_prob\n",
    "for l, lead in enumerate(np.unique(fcsts_prob.L)):\n",
    "    im = xc.view_probabilistic(fcsts_prob.isel(T=0, L=l).sel(X=slice(region_coords['west'], region_coords['east']),\n",
    "                                                                   Y=slice(region_coords['south'], region_coords['north'])), cross_dateline=True,\n",
    "                             title= region_of_interest + ' CCA MME Probabalistic Forecast for ' + target_seas[l],\n",
    "                             savefig=os.path.join(figure_dir, '_'.join(['im' + initial_month_name, target_seas[l],region_of_interest, bias_correct, 'forecast','CMORPH.png'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intdesk_train",
   "language": "python",
   "name": "intdesk_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
