import scipy.stats as ss
from core.utilities import check_all, guess_coords, check_xyt_compatibility
from core.chunking import align_chunks
import numpy as np
import xarray as xr 
import dask.array as da
from onehotupdate import quantile
import pandas as pd 
#from .spatial import regrid 

import xarray as xr
import numpy as np
import pandas as pd

def shape(X, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None):
	x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
	check_all(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
	return X.shape[list(X.dims).index(x_lat_dim)], X.shape[list(X.dims).index(x_lon_dim)], X.shape[list(X.dims).index(x_sample_dim)], X.shape[list(X.dims).index(x_feature_dim)]

often_used = { 
	'longitude': ['LONGITUDE', 'LONG', 'X', 'LON'],
	'latitude': ['LATITUDE', 'LAT', 'LATI', 'Y'],
	'sample': ['T', 'S', 'TIME', 'SAMPLES', 'SAMPLE', 'INITIALIZATION', 'INIT','D', 'DATE', "TARGET", 'YEAR', 'I', 'N'],
	'feature': ['M', 'MODE', 'FEATURES', 'F', 'REALIZATION', 'MEMBER', 'Z', 'C', 'CAT', 'NUMBER', 'V', 'VARIABLE', 'VAR', 'P', 'LEVEL'],
}
    
def regrid(X, lons, lats, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, use_dask=True, feat_chunks=1, samp_chunks=1, kind='linear'):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
    same = True
    if len(X.coords[x_lat_dim].values) == len(lats):
        for i in range(len(X.coords[x_lat_dim].values)):
            if X.coords[x_lat_dim].values[i] != lats[i]:
                same = False
    else:
        same = False
    if len(X.coords[x_lon_dim].values) == len(lons):
        for i in range(len(X.coords[x_lon_dim].values)):
            if X.coords[x_lon_dim].values[i] != lons[i]:
                same = False
    else:
        same = False
    if same:
        return X

    X1 = X.fillna(X.mean([x_lat_dim, x_lon_dim]))#fill_space_mean(X, x_lat_dim, x_lon_dim,  x_sample_dim, x_feature_dim)
    X1 = X1.chunk({x_feature_dim: max(X.shape[list(X.dims).index(x_feature_dim)] // feat_chunks, 1), x_sample_dim: max(
        X.shape[list(X.dims).index(x_sample_dim)] // samp_chunks, 1)}).transpose(x_feature_dim, x_sample_dim, x_lat_dim, x_lon_dim)

    hdf = None

    results, seldct = [], {}
    feature_ndx = 0
    for i in range(len(X1.chunks[list(X1.dims).index(x_feature_dim)])):
        sample_ndx = 0
        results.append([])
        for j in range(len(X1.chunks[list(X1.dims).index(x_sample_dim)])):
            x_isel = {x_feature_dim: slice(feature_ndx, feature_ndx + X1.chunks[list(X1.dims).index(
                x_feature_dim)][i]), x_sample_dim: slice(sample_ndx, sample_ndx + X1.chunks[list(X1.dims).index(x_sample_dim)][j])}
            results[i].append(regrid_chunk(X1.isel(**x_isel), lats, lons,  x_lat_dim, x_lon_dim,  x_sample_dim,
                              x_feature_dim, use_dask=use_dask, hdf=hdf, feature_ndx=feature_ndx, sample_ndx=sample_ndx, kind=kind))
            sample_ndx += X1.chunks[list(X1.dims).index(x_sample_dim)][j]
        feature_ndx += X1.chunks[list(X1.dims).index(x_feature_dim)][i]
        results[i] = np.concatenate(results[i], axis=1)
    results = np.concatenate(results, axis=0)

    X1 = X1.transpose(x_feature_dim, x_sample_dim, x_lat_dim, x_lon_dim)
    coords = {
        x_lat_dim: lats,
        x_lon_dim: lons,
        x_feature_dim: X1.coords[x_feature_dim].values,
        x_sample_dim: X1.coords[x_sample_dim].values
    }
    attrs = X1.attrs
    # attrs.update({'generated by': 'XCAST regrid')
    ret = xr.DataArray(data=results, coords=coords, dims=X1.dims, attrs=attrs)
    selection = {x_lat_dim: lats, x_lon_dim: lons}
    mask = X.sel(**selection, method='nearest')
    mask.coords[x_lat_dim] = lats
    mask.coords[x_lon_dim] = lons
    mask = mask.where(np.isnan(mask), other=1)
    r = ret
    r.attrs['generated_by'] = attrs['generated_by'] + \
        '\n  XCAST regridded' if 'generated_by' in attrs.keys() else '\n  XCAST regridded'
    return r * mask


def drymask(X, dry_threshold=0.001, quantile_threshold=0.33, method='quantile', x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)

    if X.dims[0] != x_lat_dim or X.dims[1] != x_lon_dim or X.dims[2] != x_sample_dim or X.dims[3] != x_feature_dim:
        X = X.transpose(x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)

    assert method.lower() in ['quantile', 'mean'], "Invalid method for drymask - must be one of ['quantile', 'mean']"

    mask2 = X.mean(x_feature_dim).mean(x_sample_dim)
    mask2 = xr.ones_like(mask2).where(~np.isnan(mask2), other=0) # 1 over present, 0 over missing

    if method.lower() == 'quantile':
        bn = quantile(X, quantile_threshold, x_lat_dim=x_lat_dim, x_lon_dim=x_lon_dim, x_sample_dim=x_sample_dim, x_feature_dim=x_feature_dim)
        mask = bn.where(bn < dry_threshold, other=np.nan) # quant where dry, nan where not
        mask = mask + mask2
        return xr.ones_like(mask).where(np.isnan(mask), other=np.nan).mean(x_feature_dim)
    elif method.lower() == 'mean':
        bn = X.mean(x_sample_dim)
        mask = bn.where(bn < dry_threshold, other=np.nan) # quant where dry, nan where not
        mask = mask + mask2
        return xr.ones_like(mask).where(np.isnan(mask), other=np.nan).mean(x_feature_dim)

def reformat(X, x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)

    X = X.assign_coords({x_lon_dim: np.asarray([ float(i - 360) if i > 180 else float(i) for i in X.coords[x_lon_dim].values]).astype(float) }).sortby(x_lon_dim).sortby(x_lat_dim)
    return X 

def match(X, Y, lat_chunks=5, lon_chunks=5,  x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None, y_lat_dim=None, y_lon_dim=None, y_sample_dim=None, y_feature_dim=None ):
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
            X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    y_lat_dim, y_lon_dim, y_sample_dim, y_feature_dim = guess_coords(
        Y, y_lat_dim, y_lon_dim, y_sample_dim, y_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(Y, y_lat_dim, y_lon_dim, y_sample_dim, y_feature_dim)

    # now reformat both of them
    X = reformat(X, x_lat_dim=x_lat_dim, x_lon_dim=x_lon_dim, x_sample_dim=x_sample_dim, x_feature_dim=x_feature_dim)
    Y = reformat(Y, x_lat_dim=y_lat_dim, x_lon_dim=y_lon_dim, x_sample_dim=y_sample_dim, x_feature_dim=y_feature_dim)

    X = regrid(X, getattr(Y, y_lon_dim), getattr(Y, y_lat_dim))
    X, Y = align_chunks(X, Y, lat_chunks=lat_chunks, lon_chunks=lon_chunks )
    check_xyt_compatibility(X, Y, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim, y_lat_dim, y_lon_dim, y_sample_dim, y_feature_dim)
    Y = Y.swap_dims({y_lon_dim: x_lon_dim, y_lat_dim: x_lat_dim, y_sample_dim: x_sample_dim}).drop(y_lon_dim).drop(y_lat_dim).drop(y_sample_dim).assign_coords({x_sample_dim: Y.coords[y_sample_dim].values, x_lat_dim: Y.coords[y_lat_dim].values, x_lon_dim: Y.coords[y_lon_dim].values})
    return X, Y

def remove_climatology(X, method='monthly', x_lat_dim=None, x_lon_dim=None, x_sample_dim=None, x_feature_dim=None):
    assert method.lower() in ['monthly'], 'invalid method, must be either daily or monthly '
    x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim = guess_coords(
        X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)
    check_all(X, x_lat_dim, x_lon_dim, x_sample_dim, x_feature_dim)

    monthly_climatology = X.groupby('{}.month'.format(x_sample_dim)).mean()
    toconcat = []
    for year in sorted(list(set( [ pd.Timestamp(i).year for i in X.coords[x_sample_dim].values] ))):
        dct = {x_sample_dim: slice(pd.Timestamp(year, 1, 1), pd.Timestamp(year, 12,31))}
        ds_yearly = X.sel(**dct).groupby('{}.month'.format(x_sample_dim)).mean() - monthly_climatology
        ds_yearly = ds_yearly.assign_coords({'month': [ pd.Timestamp(year, j, 1) for j in ds_yearly.coords['month'].values ] } ).rename({'month': x_sample_dim})
        toconcat.append(ds_yearly)
    monthly_anom = xr.concat(toconcat, x_sample_dim).sortby(x_sample_dim)
    return monthly_anom