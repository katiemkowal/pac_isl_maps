{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6ad039-4f46-4384-9cd9-47f2ff978d70",
   "metadata": {},
   "source": [
    "# Practicals: Backup Data Processing Plan, IRI Data Library\n",
    "Code to download seasonal data from IRI data library and process into netcdf if data is not available on ftp site or locally\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f959ab3-a663-459a-b03f-b0a2585135b1",
   "metadata": {},
   "source": [
    "## Conda Install\n",
    "This will require the following libraries to be installed in the conda environment, after checking they do not conflict with the int_desk train environment\n",
    "\n",
    "Run the following commands in terminal:\n",
    "\n",
    "conda activate intdesk_train\n",
    "\n",
    "conda install -c conda-forge -c iri-nextgen cptdl cptio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590892a1-23d3-4fc0-a967-c4498241ad7b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49849242-250f-4236-b2be-1266c5529486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cptdl as dl \n",
    "import cptio as cio\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20a9574-7014-4260-9c80-0a9f99edf71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory Setup, pick your project folder\n",
    "project_dir = '/Users/katie/Desktop/trial_pacisl' #setup directory where you want to work for this project\n",
    "\n",
    "#make data directores if they don't exist\n",
    "os.makedirs(os.path.join(project_dir, 'practical_data'), exist_ok = True)\n",
    "data_dir = os.path.join(project_dir, 'practical_data')\n",
    "os.makedirs(os.path.join(data_dir, 'tsv_files'), exist_ok = True)\n",
    "os.makedirs(os.path.join(data_dir, 'nc_files'), exist_ok = True)\n",
    "tsv_dir = os.path.join(data_dir, 'tsv_files')\n",
    "nc_dir = os.path.join(data_dir, 'nc_files')\n",
    "\n",
    "#sets up a month naming directory to calculate target months based on initialization month and lead times\n",
    "number_to_month_name_dictionary = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec',\n",
    "    0: 'Dec'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f57a88-82e0-4046-9e2d-842eb89cf16d",
   "metadata": {},
   "source": [
    "## Download Setup from IRI Data Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c70b4f1-ca4a-43fa-bcc8-654d9e504f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dl.observations.keys() to see all options for predictand \n",
    "# and dl.hindcasts.keys() to see all options for predictors.\n",
    "# Make sure your first_year & final_year are compatible with \n",
    "# your selections for your predictors and predictands.\n",
    "gcms = ['GEOSS2S.PRCP','SPEAR.PRCP', 'CCSM4.PRCP', 'CanSIPSIC3.PRCP', 'CFSv2.PRCP']\n",
    "#predictand_name = 'UCSB0p05.PRCP' (UCSB0p05.PRCP is 5km data, UCSB.PRCP is 25' resolution data)\n",
    "predictand_name = 'UCSB.PRCP'\n",
    "\n",
    "# 'fdate':\n",
    "#   The initialization date of the model forecasts / hindcasts.\n",
    "#   This field is defined by a python datetime.datetime object,\n",
    "#   for example: dt.datetime(2022, 5, 1) # YYYY, MM, DD as integers\n",
    "#   The year field is only used for forecasts, otherwise ignored.\n",
    "#   The day field is only used in subseasonal forecasts, otherwise ignored.\n",
    "#   The month field is an integer representing a month - ie, May=5.\n",
    "forecast_dates_of_interest = [(2023, 8, 1),(2023, 9, 1), (2023, 10, 1), (2023,11,1), (2024,1,1), (2024, 2, 1), (2023,3,1), (2024,5,1), (2024,6,1)]\n",
    "\n",
    "# lead_times will setup your target period of interest\n",
    "# lead_low will be the start and lead_high will be the end\n",
    "# for example, 1.5 and 3.5 for a forecast date of 2024,5,1 will be Jun-Aug\n",
    "lead_times = {\n",
    "'lead_low':[1.5,2.5,3.5],#1.5 month lead is the following month (e.g. for initialization in May, a forecast in June)\n",
    "'lead_high':[3.5,4.5,5.5]\n",
    "}\n",
    "\n",
    "download_args = { \n",
    "    # 'first_year':\n",
    "    #   The first year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**.\n",
    "    #   Double check that your model has hindcast data for all years in [first_year, final_year].\n",
    "    #   This field is defined by a python integer representing a year, e.g. 1993.\n",
    "    'first_year': 1993,  \n",
    "\n",
    "    # 'final_year':\n",
    "    #   The final year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**.\n",
    "    #   Double check that your model has hindcast data for all years in [first_year, final_year].\n",
    "    #   This field is defined by a python integer representing a year, e.g. 2016.\n",
    "    'final_year': 2016,  \n",
    "\n",
    "    # 'predictor_extent':\n",
    "    #   The geographic bounding box of the climate model data you want to download.\n",
    "    #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "    #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "    #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "    #   \"south\" the southernmost boundary.\n",
    "    #   Example: {\"north\": 90, \"south\": -90, \"east\": 0, \"west\": 180}\n",
    "    'predictor_extent': {\n",
    "        'west':  115,\n",
    "        'east': 260, \n",
    "        'north': 10,\n",
    "        'south': -30, \n",
    "      }, \n",
    "\n",
    "    # 'predictand_extent':\n",
    "    #   The geographic bounding box of the observation data you want to download.\n",
    "    #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "    #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "    #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "    #   \"south\" the southernmost boundary.\n",
    "    #   Example: {\"north\": 90, \"south\": -90, \"east\": 0, \"west\": 180}\n",
    "    'predictand_extent': {\n",
    "        'west':  145,\n",
    "        'east': 190,  \n",
    "        'north': 3,  \n",
    "        'south': -20, \n",
    "      },\n",
    "\n",
    "    # 'filetype':\n",
    "    #   The filetype to be downloaded. for now, it saves a lot of headache just to set this equal\n",
    "    #   to 'cptv10.tsv' which is a boutique plain-text CPT filetype based on .tsv + metadata.\n",
    "    'filetype': 'cptv10.tsv'    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb99394-0023-4ee1-ace2-b2a006029a11",
   "metadata": {},
   "source": [
    "## Download Observational Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33f154e-4d7f-4127-bf43-6c0f2ecc8396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep-Nov_UCSB.PRCP\n",
      "/Users/katie/Desktop/trial_pacisl/practical_data/nc_files/Sep-Nov_UCSB.PRCP.nc\n",
      "STARTING DOWNLOAD OF Sep-Nov_UCSB.PRCP\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRPS/.v2p0/.daily-improved/.global/.0p25/.prcp/91/mul/T/(1%20Jan%201993)/(31%20Dec%202016)/RANGE/T/%28Sep-Nov%201993-2016%29/seasonalAverage/Y/%28-20%29/%283%29/RANGEEDGES/X/%28152%29/%28185%29/RANGEEDGES/-999/setmissing_value/%5BX/Y%5D%5BT%5Dcptv10.tsv\n",
      "\n",
      "DOWNLOADING: [                         ] (0 KB) 0:00:00.000027\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTARTING DOWNLOAD OF \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obs_download_file))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tsv_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obs_download_file)))\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m---> 20\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredictand_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsv_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_download_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ml_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_dlauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     Y \u001b[38;5;241m=\u001b[39m g \u001b[38;5;241m=\u001b[39m cio\u001b[38;5;241m.\u001b[39mopen_cptdataset(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tsv_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obs_download_file)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/cptdl/utilities.py:127\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(baseurl, dest, verbose, use_dlauth, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyCPT_ERROR(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass all the required arguments for this URL as keyword arguments in .download(...). \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m URL: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ARGS: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(baseurl, kwargs))\n\u001b[0;32m--> 127\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43msimple_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_dlauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_dlauth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m    130\u001b[0m     ds \u001b[38;5;241m=\u001b[39m cio\u001b[38;5;241m.\u001b[39mopen_cptdataset(path) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcptv10.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mopen_dataset(path, decode_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/cptdl/utilities.py:103\u001b[0m, in \u001b[0;36msimple_download\u001b[0;34m(url, dest, verbose, use_dlauth)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOWNLOADING: [\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m KB) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(total_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m, dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m path\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsizeof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/urllib3/response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/site-packages/urllib3/response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m    759\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intdesk_train/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for f in forecast_dates_of_interest:\n",
    "    initial_month = dt.datetime(*f).month\n",
    "    obs_leads = []\n",
    "    for l, lead_low in enumerate(lead_times['lead_low']):\n",
    "        start_time = time.time()\n",
    "        target_low = number_to_month_name_dictionary[(initial_month + lead_low - 0.5)%12]\n",
    "        target_high = number_to_month_name_dictionary[(initial_month + lead_times['lead_high'][l] - 0.5)%12]\n",
    "        l_download = download_args.copy()\n",
    "        l_download['target'] = '-'.join([target_low, target_high])\n",
    "        l_download['lead_low'] = lead_low\n",
    "        l_download['lead_high'] = lead_times['lead_high'][l]\n",
    "    \n",
    "        obs_download_file = '_'.join([l_download['target'], predictand_name])\n",
    "        print(obs_download_file)\n",
    "\n",
    "        print(os.path.join(nc_dir,'{}.nc'.format(obs_download_file)))\n",
    "        if not Path(os.path.join(nc_dir,'{}.nc'.format(obs_download_file))).is_file():\n",
    "            print('STARTING DOWNLOAD OF {}'.format(obs_download_file))\n",
    "            if not Path(os.path.join(tsv_dir, '{}.tsv'.format(obs_download_file))).is_file():\n",
    "                Y = dl.download(dl.observations[predictand_name], os.path.join(tsv_dir,'{}.tsv'.format(obs_download_file)), **l_download, verbose=True, use_dlauth=False)\n",
    "            else:\n",
    "                Y = g = cio.open_cptdataset(os.path.join(tsv_dir, '{}.tsv'.format(obs_download_file)))\n",
    "            Y = getattr(Y, [i for i in Y.data_vars][0]).expand_dims({'M':[predictand_name]})\n",
    "            Y = Y.sortby('X')\n",
    "            Y.to_netcdf(os.path.join(nc_dir,'{}.nc'.format(obs_download_file)))\n",
    "            print()\n",
    "        else:\n",
    "            Y = xr.open_dataset(os.path.join(nc_dir, '{}.nc'.format(obs_download_file)))\n",
    "            Y = getattr(Y, [i for i in Y.data_vars][0])\n",
    "        Y = Y.expand_dims({'L':[l+1]}).swap_dims({'T':'S'})\n",
    "        print('download time is ' + str(time.time() - start_time))\n",
    "        obs_leads.append(Y)\n",
    "    nyears = []\n",
    "    for obs in obs_leads:\n",
    "        nyears.append(len(np.unique(obs.S.values)))\n",
    "    if all(i==nyears[0] for i in nyears) == True:\n",
    "        obs_leads = xr.concat(obs_leads, dim = 'L')\n",
    "    else:\n",
    "        base_obs = obs_leads[0].swap_dims({'S':'Ti'}).to_dataset(name = 'prec')\n",
    "        unique_years = np.unique(base_obs.T.dt.year.values)\n",
    "\n",
    "        updated_obs = []\n",
    "        for obs in obs_leads:\n",
    "            obs_check = obs.swap_dims({'S':'Ti'}).to_dataset(name = 'prec')\n",
    "            updated_obs.append(obs_check.sel(Ti=obs_check.Ti.dt.year.isin(unique_years)).swap_dims({'Ti':'S'}).prec)\n",
    "        obs_leads = xr.concat(updated_obs, dim = 'L')\n",
    "    splot = obs_leads.isel(L=0).swap_dims({'S':'T'}).plot(col = 'T', col_wrap = 5, subplot_kws={'projection':ccrs.PlateCarree(central_longitude=180)})\n",
    "    for ax in  splot.axs.flat:\n",
    "        coasts = ax.coastlines()\n",
    "        ax.set_xlim(download_args['predictand_extent']['west'], download_args['predictand_extent']['east'])\n",
    "        ax.set_ylim(download_args['predictand_extent']['south'], download_args['predictand_extent']['north'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4abf0-1104-4e12-a9e0-024f2f98a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfecd6-910b-45aa-9f6a-de38186ddabc",
   "metadata": {},
   "source": [
    "## Download Model Data, Including Hindcasts and Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a139d-6b0d-4b13-8bbb-57f7982e1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GCMs and save raw models to netcdf\n",
    "for f in forecast_dates_of_interest:\n",
    "    print(f)\n",
    "    iyear, imonth, iday = f # Create the datetime object for initialized data from f (stored as a tuple)\n",
    "    fdate = dt.datetime(iyear, imonth, iday)\n",
    "    initial_month = dt.datetime(*f).month\n",
    "    hindcast_data, forecast_data = [], []\n",
    "    for l, lead_low in enumerate(lead_times['lead_low']):\n",
    "        target_low = number_to_month_name_dictionary[(initial_month + lead_low - 0.5)%12]\n",
    "        target_high = number_to_month_name_dictionary[(initial_month + lead_times['lead_high'][l] - 0.5)%12]\n",
    "        l_download = download_args.copy()\n",
    "        l_download['target'] = '-'.join([target_low, target_high])\n",
    "        l_download['lead_low'] = lead_low\n",
    "        l_download['lead_high'] = lead_times['lead_high'][l]\n",
    "        l_download['fdate'] = fdate\n",
    "        hindcast_data_l, forecast_data_l = [], []\n",
    "        for gcm in gcms:\n",
    "            gcm_hindcast_download_file = '_'.join([l_download['target'], str(lead_low), str(l_download['lead_high']), 'raw_hind', gcm])\n",
    "            gcm_forecast_download_file = '_'.join([l_download['target'], str(lead_low), str(l_download['lead_high']), 'raw_fcst', gcm])\n",
    "            if not Path(os.path.join(nc_dir,'{}.nc'.format(gcm_forecast_download_file))).is_file():\n",
    "                if not Path(os.path.join(tsv_dir,'{}.tsv'.format(gcm_forecast_download_file))).is_file():\n",
    "                    print('STARTING DOWNLOAD OF {}'.format(gcm_hindcast_download_file))\n",
    "                    g = dl.download(dl.hindcasts[gcm], os.path.join(tsv_dir,'{}.tsv'.format(gcm_hindcast_download_file)), **l_download, verbose=True, use_dlauth=False)\n",
    "                    f = dl.download(dl.forecasts[gcm], os.path.join(tsv_dir,'{}.tsv'.format(gcm_forecast_download_file)), **l_download, verbose=True, use_dlauth=False)\n",
    "                    g = getattr(g, [i for i in g.data_vars][0])\n",
    "                    f = getattr(f, [i for i in f.data_vars][0])\n",
    "                    print()\n",
    "                else:\n",
    "                    print('LOADING {} FROM FILE'.format(gcm_hindcast_download_file))\n",
    "                    g = cio.open_cptdataset(os.path.join(tsv_dir, '{}.tsv'.format(gcm_hindcast_download_file)))\n",
    "                    f = cio.open_cptdataset(os.path.join(tsv_dir, '{}.tsv'.format(gcm_forecast_download_file)))\n",
    "                    print()\n",
    "                    g = getattr(g, [i for i in g.data_vars][0])\n",
    "                    f = getattr(f, [i for i in f.data_vars][0])\n",
    "                #label datasets by model name\n",
    "                g = g.expand_dims({'M':[gcm]})\n",
    "                f = f.expand_dims({'M':[gcm]})\n",
    "\n",
    "                #regrid models to observation coordinates for consistent grids across models\n",
    "                #g = xc.regrid(g, Y.coords['X'].values, Y.coords['Y'].values)\n",
    "                #f = xc.regrid(f, Y.coords['X'].values, Y.coords['Y'].values)\n",
    "\n",
    "                nc_prep = xr.concat(g, 'M')\n",
    "                nc_prep.to_netcdf(os.path.join(nc_dir,'{}.nc'.format(gcm_hindcast_download_file)))\n",
    "                f_nc_prep = xr.concat(f, 'M')\n",
    "                f_nc_prep.to_netcdf(os.path.join(nc_dir, '{}.nc'.format(gcm_forecast_download_file)))\n",
    "            else:\n",
    "                g = xr.open_dataset(os.path.join(nc_dir,'{}.nc'.format(gcm_hindcast_download_file))).prec\n",
    "                f = xr.open_dataset(os.path.join(nc_dir,'{}.nc'.format(gcm_forecast_download_file))).prec\n",
    "            hindcast_data_l.append(g)\n",
    "            forecast_data_l.append(f)\n",
    "        hindcast_data_l = xr.concat(hindcast_data_l, dim = 'M')\n",
    "        forecast_data_l = xr.concat(forecast_data_l, dim = 'M')\n",
    "        hindcast_data_l = hindcast_data_l.expand_dims({'L':[l+1]}).swap_dims({'T':'S'})\n",
    "        forecast_data_l = forecast_data_l.expand_dims({'L':[l+1]}).swap_dims({'T':'S'})\n",
    "        hindcast_data.append(hindcast_data_l)\n",
    "        forecast_data.append(forecast_data_l)\n",
    "    hindcast_data = xr.concat(hindcast_data, dim = 'L')\n",
    "    forecast_data = xr.concat(forecast_data, dim = 'L')\n",
    "    \n",
    "    print('one month initialization')\n",
    "    splot = hindcast_data.isel(L = 0).swap_dims({'S':'T'}).isel(T=0).plot(col = 'M', col_wrap = 5, subplot_kws={'projection':ccrs.PlateCarree(central_longitude=180)})\n",
    "    for ax in  splot.axs.flat:\n",
    "        ax.set_xlim(download_args['predictand_extent']['west'], download_args['predictand_extent']['east'])\n",
    "        ax.set_ylim(download_args['predictand_extent']['south'], download_args['predictand_extent']['north'])\n",
    "        ax.coastlines(\"10m\", alpha=0.1, zorder=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6904c-cba8-4481-887c-6c48ae67de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intdesk_train",
   "language": "python",
   "name": "intdesk_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
